project_name: "cs336-exp6-arch-llama"

common:
  data:
    train_path: "output/owt_train.npy"
    val_path: "output/owt_valid.npy"
  training:
    device: "cuda"
    batch_size: 64
    max_iters: 25000  # 适当调整步数
    learning_rate: 3e-4
    min_lr: 3e-5
    warmup_iters: 1000
    weight_decay: 0.1
    beta1: 0.9
    beta2: 0.95
    eps: 1e-8
    grad_clip: 1.0
  checkpoint:
    out_dir_base: "checkpoints/exp1"
    save_interval: 2000

experiments:
  # Vanilla (Original) 架构
  - run_name: "Vanilla-Architecture"
    model:
      vocab_size: 10000
      context_length: 256
      d_model: 256
      num_layers: 4
      num_heads: 4
      d_ff: 1024           # ReLU 维度 (256 * 4 = 1024)
      rope_theta: 10000.0
      pos_emb_type: "learned"
      norm_location: "post"
      norm_type: "layernorm"
      ffn_type: "relu"
      weight_tying: true
      dropout: 0.1